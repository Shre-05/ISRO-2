# ISRO-2

## ğŸ§  Problem Statement 2: AI Help Bot for Knowledge Retrieval from Web Portal

---

## ğŸ“Œ 1. Project Overview

**MOSDACQueryBot** is a lightweight **AI-driven help assistant** designed to simplify information retrieval from the [MOSDAC Portal](https://www.mosdac.gov.in). The platform hosts a variety of satellite datasets, FAQs, and documentation. Navigating through its layered and scattered content is time-consuming for users.

Our solution uses **Natural Language Processing (NLP)** and **knowledge graph-based reasoning** to intelligently fetch answers from structured and unstructured web content â€” documents, FAQs, and web pages â€” with an easy-to-use chatbot interface.

Using **LangChain**, **spaCy**, **OpenAI Embeddings**, and optionally **LLMs**, this project enables contextual, fast, and accurate query answering in a short time.

---

## ğŸŒŸ 2. Project Objectives

* ğŸ¤– Build an AI-based **virtual assistant** that answers user queries from the MOSDAC portal.
* ğŸ§± Convert static/dynamic content into a **knowledge graph** (entities and relationships).
* ğŸ§  Use NLP for **intent classification**, **entity extraction**, and **semantic retrieval**.
* ğŸ—£ï¸ Enable a **conversational interface** that understands context and follows multi-turn dialogs.
* ğŸ”„ Ensure modularity for deployment across similar government portals.

---

## ğŸ“¦ 3. Dataset Overview

| Content Type     | Source                                     | Description                                     |
| ---------------- | ------------------------------------------ | ----------------------------------------------- |
| ğŸ“„ Web Pages     | [MOSDAC.gov.in](https://www.mosdac.gov.in) | FAQ, documentation, static content              |
| ğŸ“ Documents     | Download sections                          | PDFs, XLSX, DOCs with technical info            |
| ğŸ§¾ Metadata      | HTML + ARIA tags                           | Categories, tags, page sections, menu structure |
| ğŸŒ Product Pages | Dynamic navigation                         | Real-time product data and mission info         |

ğŸ“ **Formats**: HTML, PDF, DOCX, XLSX
ğŸ§¹ **Preprocessing**: Content scraping, text extraction (using `BeautifulSoup`, `pdfminer`, `docx`, `tabula-py`)

---

## ğŸ› ï¸ 4. Tools and Technologies

| Tool / Library         | Purpose                                          |
| ---------------------- | ------------------------------------------------ |
| ğŸ Python              | Core development                                 |
| ğŸ§  spaCy / NLTK        | NLP and entity extraction                        |
| ğŸ§© LangChain           | Knowledge graph creation + query chain           |
| ğŸ“š OpenAI Embeddings   | Semantic similarity for retrieval                |
| ğŸ”— NetworkX / Neo4j    | Graph database or in-memory graph representation |
| ğŸ’¬ Streamlit / Gradio  | Chatbot front-end UI                             |
| ğŸ•¸ï¸ BeautifulSoup      | HTML parsing and web scraping                    |
| ğŸ“œ pdfminer / docx2txt | PDF and Word document parsing                    |

---

## ğŸ”§ 5. Methodology (Simplified Workflow)

```plaintext
       +-----------------------------+
       |    Static + Dynamic Data    |
       |  (HTML, PDF, XLSX, DOCX)    |
       +-----------------------------+
                    |
         +------------------------+
         | Text Extraction Engine |
         +------------------------+
                    |
     +-------------------------------+
     |   Entity & Relationship NLP   |
     +-------------------------------+
                    |
     +-------------------------------+
     |  Knowledge Graph Construction |
     +-------------------------------+
                    |
     +-------------------------------+
     | User Query (via Chatbot UI)  |
     +-------------------------------+
                    |
     +-----------------------------+
     | Semantic Search + Answering |
     +-----------------------------+
                    |
     +-----------------------------+
     |  Final Response (Text/Card) |
     +-----------------------------+
```

---

## ğŸ‘¥ 6. Team Task Distribution (Parallel Modules)

### ğŸ‘©â€ğŸ’» Member 1 â€“ Web Scraping & Document Parsing

* Scrape static pages using `requests` + `BeautifulSoup`
* Extract content from PDFs using `pdfminer.six` / `PyMuPDF`
* Parse `.docx`, `.xlsx` using `python-docx`, `openpyxl`
* Preprocess and clean text

ğŸ“¤ Output: `.txt` files + metadata JSON

---

### ğŸ‘¨â€ğŸ’» Member 2 â€“ NLP Entity Extraction & Graph Building

* Use **spaCy/NLTK** to identify:

  * Entities (e.g., satellites, products)
  * Relationships (e.g., "belongs to", "used in")
* Build graph using `NetworkX` or `Neo4j`
* Export in `.graphml` or `.json`

ğŸ“¤ Output: Knowledge Graph + embeddings (optional)

---

### ğŸ‘©â€ğŸ’» Member 3 â€“ Chatbot & Retrieval Engine

* Build retrieval chain using **LangChain + OpenAI Embeddings**
* Support context-aware question answering
* Design prompt templates for fallback answers
* Integrate semantic search with knowledge graph

ğŸ“¤ Output: Query â†’ Semantic â†’ Matched Answer

---

### ğŸ‘¨â€ğŸ’» Member 4 â€“ Frontend UI + Integration

* Build Streamlit or Gradio chatbot interface
* Integrate backend APIs for question response
* Enable upload of custom files (for testing)
* Add session memory & conversation history

ğŸ“¤ Output: Web-based interactive chatbot UI

---

## ğŸ§ª 7. Novelty Statement

Our approach is **simple yet modular** because:

* ğŸ§  Combines **structured KG reasoning** with **semantic retrieval**
* ğŸ”„ Allows **live interaction** on government data (not static documents alone)
* ğŸ§± Converts heterogeneous content into a unified knowledge system
* ğŸ“¦ Packaged for **reuse across other public data portals**

---

## ğŸ—‚ï¸ 8. GitHub Folder Structure

```plaintext
mosdac-querybot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ html_pages/           # Scraped content
â”‚   â”œâ”€â”€ docs_parsed/          # Parsed PDF/DOCX/XLSX
â”‚   â””â”€â”€ kg_data/              # JSON or GraphML files
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extractor/            # Web/document text parsing
â”‚   â”œâ”€â”€ nlp_graph/            # spaCy-based entity/graph model
â”‚   â”œâ”€â”€ chatbot_backend/      # LangChain + vector search
â”‚   â””â”€â”€ ui_streamlit/         # Frontend chatbot interface
â”œâ”€â”€ notebooks/                # Debug, analysis notebooks
â”œâ”€â”€ results/                  # Logs, screenshots, sample runs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ˆ 9. Evaluation Metrics

| Component              | Metric                                     |
| ---------------------- | ------------------------------------------ |
| ğŸ” Intent Recognition  | Classification Accuracy (%)                |
| ğŸ§  Entity Extraction   | Precision / Recall of key entity matches   |
| ğŸ” Context Consistency | Score of multi-turn dialog retention       |
| ğŸ’¬ Response Accuracy   | User rating or BLEU-style similarity score |
| â±ï¸ Latency & Speed     | Response time (ms) under load              |

---

## ğŸ“š 10. References

* [MOSDAC Official Portal](https://www.mosdac.gov.in)
* [LangChain Documentation](https://docs.langchain.com/)
* [spaCy NLP Toolkit](https://spacy.io/)
* [pdfminer for Python](https://github.com/pdfminer/pdfminer.six)
* [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
* [Streamlit](https://streamlit.io/), [Gradio](https://gradio.app/)

